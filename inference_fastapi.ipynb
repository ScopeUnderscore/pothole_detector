{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVNnikeZMnso",
        "outputId": "d9bb8273-856a-4041-fb58-f8b1464f2933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/974.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m870.4/974.5 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.5/974.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#Install Dependencies and Setup FastAPI Server\n",
        "!pip install -q ultralytics fastapi uvicorn pyngrok python-multipart -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "oz6Oq4wlNYi6",
        "outputId": "3fa4fc93-b4a5-41d9-aa27-d314bc45d242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your YOLOv11 model weights (best.pt):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95097240-9ae9-47a6-b2be-0641da7ad9f9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95097240-9ae9-47a6-b2be-0641da7ad9f9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best_remya.pt to best_remya.pt\n"
          ]
        }
      ],
      "source": [
        "# Upload your model\n",
        "from google.colab import files\n",
        "print(\"Please upload your YOLOv11 model weights (best.pt):\")\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmKJp6_NP01L",
        "outputId": "9a2f7546-aedd-4496-b83e-55d0250ad33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "import io\n",
        "import cv2\n",
        "import base64\n",
        "import numpy as np\n",
        "from fastapi import FastAPI, File, UploadFile, Form, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "import uvicorn\n",
        "from typing import List, Optional, Union\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "# Import your model loader\n",
        "# For Colab, you'll need to adapt how you load the model\n",
        "from model_loader import load_model\n",
        "\n",
        "# Load the YOLO model\n",
        "model = load_model()\n",
        "\n",
        "app = FastAPI(title=\"Pothole Detection API\")\n",
        "\n",
        "# Allow CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],  # In production, replace with your Django domain\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class PotholeDetection(BaseModel):\n",
        "    pothole_detected: bool\n",
        "    severity: float\n",
        "    image_base64: Optional[str] = None\n",
        "    detections: List[dict] = []\n",
        "\n",
        "class VideoAnalysisResult(BaseModel):\n",
        "    average_severity: float\n",
        "    damaged_road_percentage: float\n",
        "    video_base64: Optional[str] = None\n",
        "    total_potholes_detected: int\n",
        "\n",
        "def decode_image(image_data):\n",
        "    \"\"\"Convert base64 or file data to OpenCV image\"\"\"\n",
        "    try:\n",
        "        # For base64 encoded images\n",
        "        if isinstance(image_data, str) and image_data.startswith('data:image'):\n",
        "            # Extract base64 content after the comma\n",
        "            base64_data = image_data.split(',')[1]\n",
        "            image_bytes = base64.b64decode(base64_data)\n",
        "        elif isinstance(image_data, str):\n",
        "            # Already base64 without data URI scheme\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "        else:\n",
        "            # For direct file uploads\n",
        "            image_bytes = image_data\n",
        "\n",
        "        nparr = np.frombuffer(image_bytes, np.uint8)\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is None:\n",
        "            raise ValueError(\"Failed to decode image\")\n",
        "\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Invalid image data: {str(e)}\")\n",
        "\n",
        "def encode_image_to_base64(cv_image):\n",
        "    \"\"\"Convert OpenCV image to base64 string\"\"\"\n",
        "    _, buffer = cv2.imencode('.jpg', cv_image)\n",
        "    return base64.b64encode(buffer).decode('utf-8')\n",
        "\n",
        "@app.post(\"/predict-image/\", response_model=PotholeDetection)\n",
        "async def predict_pothole(file: Union[UploadFile, None] = None, image_base64: str = Form(None)):\n",
        "    \"\"\"\n",
        "    Process an image to detect potholes. Accepts either file upload or base64 image.\n",
        "    \"\"\"\n",
        "    if file is None and image_base64 is None:\n",
        "        raise HTTPException(status_code=400, detail=\"Either file or image_base64 must be provided\")\n",
        "\n",
        "    try:\n",
        "        # Process based on input type\n",
        "        if file:\n",
        "            contents = await file.read()\n",
        "            img = decode_image(contents)\n",
        "        else:\n",
        "            img = decode_image(image_base64)\n",
        "\n",
        "        # **Step 2: Perform inference using YOLO model**\n",
        "        results_list = model.predict(img)\n",
        "\n",
        "        if not results_list or results_list[0].masks is None:  # No detections\n",
        "            return {\n",
        "                \"pothole_detected\": False,\n",
        "                \"severity\": 0.0,\n",
        "                \"image_base64\": encode_image_to_base64(img),\n",
        "                \"detections\": [],\n",
        "            }\n",
        "\n",
        "        results = results_list[0]  # Extract first result\n",
        "        masks = results.masks.data.cpu().numpy()  # Get segmentation masks\n",
        "        confidences = results.boxes.conf.cpu().numpy()  # Get confidence scores\n",
        "\n",
        "        # **Compute Image Area**\n",
        "        image_height, image_width, _ = img.shape\n",
        "        image_area = image_height * image_width\n",
        "\n",
        "        # **Initialize mask and area storage**\n",
        "        total_pothole_area = 0\n",
        "        pothole_areas = []\n",
        "        combined_mask = np.zeros((image_height, image_width), dtype=np.uint8)  # Accumulate all pothole masks\n",
        "        pothole_detections = []\n",
        "\n",
        "        for i, (mask, confidence) in enumerate(zip(masks, confidences)):\n",
        "            pothole_number = i + 1  # Assign a unique number to each pothole\n",
        "            binary_mask = (mask > 0).astype(np.uint8) * 255  # Convert mask to binary\n",
        "            combined_mask = cv2.bitwise_or(combined_mask, binary_mask)  # Merge masks\n",
        "\n",
        "            contours, _ = cv2.findContours(\n",
        "                binary_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
        "            )\n",
        "\n",
        "            if len(contours) == 0:\n",
        "                print(f\"Warning: No contours found for pothole {pothole_number}\")\n",
        "                continue  # Skip this mask\n",
        "\n",
        "            # Get the largest contour area (for pothole)\n",
        "            contour = max(contours, key=cv2.contourArea)\n",
        "            area = cv2.contourArea(contour)\n",
        "            total_pothole_area += area\n",
        "\n",
        "            # Compute Pothole Percentage\n",
        "            pothole_percentage = (area / image_area) * 100\n",
        "            pothole_areas.append(f\"Pothole {pothole_number}: {pothole_percentage:.2f}%\")\n",
        "\n",
        "            # Store detection info\n",
        "            pothole_detections.append({\n",
        "                \"pothole_number\": pothole_number,\n",
        "                \"confidence\": round(float(confidence), 2),\n",
        "                \"pothole_percentage\": round(pothole_percentage, 2),\n",
        "            })\n",
        "\n",
        "            # **Step 5: Draw contours and assign a pothole number**\n",
        "            cv2.drawContours(img, [contour], -1, (0, 255, 0), thickness=3)\n",
        "\n",
        "            # Get bounding box for placing the pothole number\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            cv2.putText(\n",
        "                img, str(pothole_number), (x + w // 2, y + h // 2),  # Place number inside pothole\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2\n",
        "            )\n",
        "\n",
        "        # **Step 6: Compute severity percentage**\n",
        "        severity_percentage = (total_pothole_area / image_area) * 100 if image_area > 0 else 0\n",
        "\n",
        "        # **Step 7: Overlay segmentation mask (Now covering all potholes)**\n",
        "        colored_mask = cv2.applyColorMap(combined_mask, cv2.COLORMAP_JET)\n",
        "        masked_img = cv2.addWeighted(img, 0.6, colored_mask, 0.4, 0)\n",
        "\n",
        "        # **Step 8: Display Summary Labels at the Top-Left (No Black Background)**\n",
        "        summary_text = f\"Total Damage: {severity_percentage:.2f}%\"\n",
        "\n",
        "        # Draw white text with black shadow for visibility\n",
        "        cv2.putText(masked_img, summary_text, (15, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 3)  # Shadow\n",
        "        cv2.putText(masked_img, summary_text, (15, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)  # Main Text\n",
        "\n",
        "        # Display individual pothole percentages below the total\n",
        "        y_offset = 60\n",
        "        for pothole_info in pothole_areas:\n",
        "            cv2.putText(masked_img, pothole_info, (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3)  # Shadow\n",
        "            cv2.putText(masked_img, pothole_info, (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)  # Main Text\n",
        "            y_offset += 20\n",
        "\n",
        "        # Encode the processed image to base64\n",
        "        processed_image_base64 = encode_image_to_base64(masked_img)\n",
        "\n",
        "        return {\n",
        "            \"pothole_detected\": True,\n",
        "            \"severity\": round(severity_percentage, 2),\n",
        "            \"image_base64\": processed_image_base64,  # Return processed image as base64\n",
        "            \"detections\": pothole_detections,  # Confidence scores and pothole percentages\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing image: {str(e)}\")\n",
        "\n",
        "\n",
        "@app.post(\"/process-video/\", response_model=VideoAnalysisResult)\n",
        "async def process_video(file: UploadFile = File(...)):\n",
        "    \"\"\"\n",
        "    Process a video file to detect potholes\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Save uploaded video to a temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_video:\n",
        "            temp_video_path = temp_video.name\n",
        "            temp_video.write(await file.read())\n",
        "\n",
        "        # Process the video (adapted from your video_processing.py)\n",
        "        cap = cv2.VideoCapture(temp_video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise HTTPException(status_code=400, detail=f\"Unable to open video file\")\n",
        "\n",
        "        width, height = (\n",
        "            int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "            int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "        )\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        processed_video_path = \"temp_processed_video.mp4\"\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        out = cv2.VideoWriter(processed_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "        frame_count = 0\n",
        "        total_severity = 0\n",
        "        unique_potholes = set()\n",
        "\n",
        "        global_road_mask = np.zeros((height, width), dtype=np.uint8)  # Store total visible road\n",
        "        global_pothole_mask = np.zeros((height, width), dtype=np.uint8)  # Store all potholes\n",
        "\n",
        "        orb = cv2.ORB_create(500)\n",
        "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "        prev_frame_gray = None\n",
        "        prev_kp = None\n",
        "        prev_des = None\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            homography_matrix = None\n",
        "\n",
        "            # Compute Homography\n",
        "            if prev_frame_gray is not None:\n",
        "                kp, des = orb.detectAndCompute(gray_frame, None)\n",
        "                if kp and des is not None and prev_kp is not None and prev_des is not None:\n",
        "                    matches = bf.match(des, prev_des)\n",
        "                    matches = sorted(matches, key=lambda x: x.distance)[:50]\n",
        "\n",
        "                    if len(matches) > 10:\n",
        "                        src_pts = np.float32([kp[m.queryIdx].pt for m in matches]).reshape(\n",
        "                            -1, 1, 2\n",
        "                        )\n",
        "                        dst_pts = np.float32(\n",
        "                            [prev_kp[m.trainIdx].pt for m in matches]\n",
        "                        ).reshape(-1, 1, 2)\n",
        "                        homography_matrix, _ = cv2.findHomography(\n",
        "                            src_pts, dst_pts, cv2.RANSAC, 5.0\n",
        "                        )\n",
        "\n",
        "            prev_frame_gray = gray_frame.copy()\n",
        "            prev_kp, prev_des = orb.detectAndCompute(gray_frame, None)\n",
        "\n",
        "            # Run YOLO segmentation model on the frame\n",
        "            results_list = model.predict(frame, show=False)\n",
        "            if not results_list:\n",
        "                out.write(frame)\n",
        "                continue\n",
        "\n",
        "            results = results_list[0]\n",
        "            masks = results.masks\n",
        "            boxes = results.boxes\n",
        "\n",
        "            binary_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
        "            detected_potholes = []\n",
        "\n",
        "            if boxes is not None:\n",
        "                for box in boxes:\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                    confidence = float(box.conf[0])\n",
        "\n",
        "                    center_x = (x1 + x2) // 2\n",
        "                    center_y = (y1 + y2) // 2\n",
        "                    pothole_id = (center_x // 10, center_y // 10)\n",
        "\n",
        "                    if pothole_id not in unique_potholes:\n",
        "                        unique_potholes.add(pothole_id)\n",
        "\n",
        "                    detected_potholes.append((x1, y1, x2, y2, confidence))\n",
        "\n",
        "            if masks is not None and hasattr(masks, \"data\"):\n",
        "                mask_data = masks.data.cpu().numpy()\n",
        "                for mask in mask_data:\n",
        "                    mask = (mask * 255).astype(np.uint8)\n",
        "                    mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]))\n",
        "                    binary_mask = cv2.bitwise_or(binary_mask, mask_resized)\n",
        "\n",
        "            # If homography is available, align binary mask\n",
        "            if homography_matrix is not None:\n",
        "                binary_mask = cv2.warpPerspective(\n",
        "                    binary_mask, homography_matrix, (width, height)\n",
        "                )\n",
        "\n",
        "            # Update Global Road Mask\n",
        "            new_road_pixels = (\n",
        "                (frame[:, :, 0] > 50) | (frame[:, :, 1] > 50) | (frame[:, :, 2] > 50)\n",
        "            )\n",
        "            global_road_mask[new_road_pixels] = 255\n",
        "\n",
        "            # Update Global Pothole Mask\n",
        "            global_pothole_mask = cv2.bitwise_or(global_pothole_mask, binary_mask)\n",
        "\n",
        "            total_road_pixels = np.sum(global_road_mask > 0)\n",
        "            total_pothole_pixels = np.sum(global_pothole_mask > 0)\n",
        "\n",
        "            current_damage = (\n",
        "                (np.sum(binary_mask > 0) / np.sum(global_road_mask > 0)) * 100\n",
        "                if np.sum(global_road_mask > 0) > 0\n",
        "                else 0\n",
        "            )\n",
        "            total_damage = (\n",
        "                (total_pothole_pixels / total_road_pixels) * 100\n",
        "                if total_road_pixels > 0\n",
        "                else 0\n",
        "            )\n",
        "\n",
        "            total_severity += current_damage\n",
        "\n",
        "            # Display Labels\n",
        "            cv2.putText(\n",
        "                frame,\n",
        "                f\"Total Damage: {((total_damage)*(1/2)):.2f}%\",\n",
        "                (20, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.8,\n",
        "                (0, 0, 255),\n",
        "                2,\n",
        "            )\n",
        "\n",
        "            cv2.putText(\n",
        "                frame,\n",
        "                f\"Current Frame: {current_damage:.2f}%\",\n",
        "                (20, 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                0.8,\n",
        "                (255, 0, 0),\n",
        "                2,\n",
        "            )\n",
        "\n",
        "            # Draw pothole contours\n",
        "            contours, _ = cv2.findContours(\n",
        "                binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "            )\n",
        "            for contour in contours:\n",
        "                cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "            mask_colored = cv2.merge(\n",
        "                [np.zeros_like(binary_mask), np.zeros_like(binary_mask), binary_mask]\n",
        "            )\n",
        "            frame = cv2.addWeighted(frame, 0.6, mask_colored, 0.4, 0)\n",
        "\n",
        "            for x1, y1, x2, y2, confidence in detected_potholes:\n",
        "                cv2.putText(\n",
        "                    frame,\n",
        "                    f\"{confidence:.2f}\",\n",
        "                    (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    0.6,\n",
        "                    (0, 255, 0),\n",
        "                    2,\n",
        "                )\n",
        "\n",
        "            if frame.shape != (height, width, 3):\n",
        "                frame = cv2.resize(frame, (width, height))\n",
        "\n",
        "            out.write(frame)\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        avg_severity = total_severity / frame_count if frame_count > 0 else 0\n",
        "        total_potholes_detected = len(unique_potholes)\n",
        "\n",
        "        # Read the processed video file and convert to base64\n",
        "        with open(processed_video_path, \"rb\") as video_file:\n",
        "            video_content = video_file.read()\n",
        "            video_base64 = base64.b64encode(video_content).decode('utf-8')\n",
        "\n",
        "        # Clean up temporary files\n",
        "        os.remove(temp_video_path)\n",
        "        os.remove(processed_video_path)\n",
        "\n",
        "        return {\n",
        "            \"average_severity\": round(avg_severity, 2),\n",
        "            \"damaged_road_percentage\": round(total_damage * (1/2), 2),\n",
        "            \"video_base64\": video_base64,\n",
        "            \"total_potholes_detected\": total_potholes_detected,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        # Clean up in case of error\n",
        "        if 'temp_video_path' in locals() and os.path.exists(temp_video_path):\n",
        "            os.remove(temp_video_path)\n",
        "        if 'processed_video_path' in locals() and os.path.exists(processed_video_path):\n",
        "            os.remove(processed_video_path)\n",
        "\n",
        "        raise HTTPException(status_code=500, detail=f\"Error processing video: {str(e)}\")\n",
        "\n",
        "\n",
        "# For running in Colab with ngrok\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "id": "J7VZ2Uj2EMFl",
        "outputId": "f705b299-742a-4400-c842-3158ffb1a86b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import cv2\n",
        "import base64\n",
        "import numpy as np\n",
        "from fastapi import FastAPI, File, UploadFile, Form, HTTPException\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel, HttpUrl\n",
        "import uvicorn\n",
        "from typing import List, Optional, Union\n",
        "import tempfile\n",
        "import requests\n",
        "import nest_asyncio\n",
        "from fastapi.responses import JSONResponse\n",
        "\n",
        "# Apply nest_asyncio to allow running asyncio within Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Import your model loader\n",
        "# For Colab, you'll need to adapt how you load the model\n",
        "from model_loader import load_model\n",
        "\n",
        "# Load the YOLO model\n",
        "model = load_model()\n",
        "\n",
        "app = FastAPI(title=\"Pothole Detection API\")\n",
        "\n",
        "# Allow CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class PotholeDetection(BaseModel):\n",
        "    pothole_detected: bool\n",
        "    severity: float\n",
        "    image_base64: Optional[str] = None\n",
        "    detections: List[dict] = []\n",
        "\n",
        "class VideoAnalysisResult(BaseModel):\n",
        "    average_severity: float\n",
        "    damaged_road_percentage: float\n",
        "    video_base64: Optional[str] = None\n",
        "    total_potholes_detected: int\n",
        "\n",
        "\n",
        "class VideoURLRequest(BaseModel):\n",
        "  video_url:HttpUrl\n",
        "\n",
        "\n",
        "def decode_image(image_data):\n",
        "    \"\"\"Convert base64 or file data to OpenCV image\"\"\"\n",
        "    try:\n",
        "        # For base64 encoded images\n",
        "        if isinstance(image_data, str) and image_data.startswith('data:image'):\n",
        "            # Extract base64 content after the comma\n",
        "            base64_data = image_data.split(',')[1]\n",
        "            image_bytes = base64.b64decode(base64_data)\n",
        "        elif isinstance(image_data, str):\n",
        "            # Already base64 without data URI scheme\n",
        "            image_bytes = base64.b64decode(image_data)\n",
        "        else:\n",
        "            # For direct file uploads\n",
        "            image_bytes = image_data\n",
        "\n",
        "        nparr = np.frombuffer(image_bytes, np.uint8)\n",
        "        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is None:\n",
        "            raise ValueError(\"Failed to decode image\")\n",
        "\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Invalid image data: {str(e)}\")\n",
        "\n",
        "def encode_image_to_base64(cv_image):\n",
        "    \"\"\"Convert OpenCV image to base64 string\"\"\"\n",
        "    _, buffer = cv2.imencode('.jpg', cv_image)\n",
        "    return base64.b64encode(buffer).decode('utf-8')\n",
        "\n",
        "def process_image_with_model(img):\n",
        "    \"\"\"Process image with YOLO model and return results\"\"\"\n",
        "    # Perform inference\n",
        "    results_list = model.predict(img)\n",
        "\n",
        "    # Handle case with no detections\n",
        "    if not results_list or not hasattr(results_list[0], 'masks') or results_list[0].masks is None:\n",
        "        return {\n",
        "            \"pothole_detected\": False,\n",
        "            \"severity\": 0.0,\n",
        "            \"image_base64\": encode_image_to_base64(img),\n",
        "            \"detections\": [],\n",
        "        }\n",
        "\n",
        "    results = results_list[0]\n",
        "\n",
        "    # Get image dimensions\n",
        "    image_height, image_width, _ = img.shape\n",
        "    image_area = image_height * image_width\n",
        "\n",
        "    # Extract masks and confidences\n",
        "    masks = results.masks.data.cpu().numpy()\n",
        "    confidences = results.boxes.conf.cpu().numpy()\n",
        "\n",
        "    # Initialize processing variables\n",
        "    total_pothole_area = 0\n",
        "    pothole_areas = []\n",
        "    combined_mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
        "    pothole_detections = []\n",
        "\n",
        "    # Process each detected pothole\n",
        "    for i, (mask, confidence) in enumerate(zip(masks, confidences)):\n",
        "        pothole_number = i + 1\n",
        "\n",
        "        # Convert mask to binary\n",
        "        binary_mask = (mask > 0).astype(np.uint8) * 255\n",
        "        combined_mask = cv2.bitwise_or(combined_mask, binary_mask)\n",
        "\n",
        "        # Find contours in the mask\n",
        "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if not contours:\n",
        "            continue\n",
        "\n",
        "        # Get largest contour (pothole)\n",
        "        contour = max(contours, key=cv2.contourArea)\n",
        "        area = cv2.contourArea(contour)\n",
        "        total_pothole_area += area\n",
        "\n",
        "        # Calculate pothole percentage\n",
        "        pothole_percentage = (area / image_area) * 100\n",
        "        pothole_areas.append(f\"Pothole {pothole_number}: {pothole_percentage:.2f}%\")\n",
        "\n",
        "        # Store detection info\n",
        "        pothole_detections.append({\n",
        "            \"pothole_number\": pothole_number,\n",
        "            \"confidence\": round(float(confidence), 2),\n",
        "            \"pothole_percentage\": round(pothole_percentage, 2),\n",
        "        })\n",
        "\n",
        "        # Draw contours and label\n",
        "        cv2.drawContours(img, [contour], -1, (0, 255, 0), thickness=3)\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        cv2.putText(img, str(pothole_number), (x + w // 2, y + h // 2),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "    # Calculate overall severity\n",
        "    severity_percentage = (total_pothole_area / image_area) * 100 if image_area > 0 else 0\n",
        "\n",
        "    # Create visualization with mask overlay\n",
        "    colored_mask = cv2.applyColorMap(combined_mask, cv2.COLORMAP_JET)\n",
        "    masked_img = cv2.addWeighted(img, 0.6, colored_mask, 0.4, 0)\n",
        "\n",
        "    # Add summary text\n",
        "    summary_text = f\"Total Damage: {severity_percentage:.2f}%\"\n",
        "    cv2.putText(masked_img, summary_text, (15, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 3)\n",
        "    cv2.putText(masked_img, summary_text, (15, 35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "    # Add individual pothole percentages\n",
        "    y_offset = 60\n",
        "    for pothole_info in pothole_areas:\n",
        "        cv2.putText(masked_img, pothole_info, (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 3)\n",
        "        cv2.putText(masked_img, pothole_info, (15, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
        "        y_offset += 20\n",
        "\n",
        "    # Return results\n",
        "    return {\n",
        "        \"pothole_detected\": True,\n",
        "        \"severity\": round(severity_percentage, 2),\n",
        "        \"image_base64\": encode_image_to_base64(masked_img),\n",
        "        \"detections\": pothole_detections,\n",
        "    }\n",
        "\n",
        "@app.post(\"/predict-image/\", response_model=PotholeDetection)\n",
        "async def predict_pothole(file: Union[UploadFile, None] = None, image_base64: str = Form(None)):\n",
        "    \"\"\"\n",
        "    Process an image to detect potholes. Accepts either file upload or base64 image.\n",
        "    \"\"\"\n",
        "    if file is None and image_base64 is None:\n",
        "        raise HTTPException(status_code=400, detail=\"Either file or image_base64 must be provided\")\n",
        "\n",
        "    try:\n",
        "        # Process based on input type\n",
        "        if file:\n",
        "            contents = await file.read()\n",
        "            img = decode_image(contents)\n",
        "        else:\n",
        "            img = decode_image(image_base64)\n",
        "\n",
        "        # Process the image with the model\n",
        "        return process_image_with_model(img)\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        return JSONResponse(\n",
        "            status_code=500,\n",
        "            content={\"detail\": f\"Error processing image: {str(e)}\",\n",
        "                     \"traceback\": traceback.format_exc()}\n",
        "        )\n",
        "\n",
        "@app.post(\"/process-video/\", response_model=VideoAnalysisResult)\n",
        "# async def process_video(file: UploadFile = File(...)):\n",
        "async def process_video(request: VideoURLRequest):\n",
        "    \"\"\"\n",
        "    # Process a video file to detect potholes\n",
        "\n",
        "    \"\"\"\n",
        "    video_url = request.video_url\n",
        "    temp_video_path = None\n",
        "    # processed_video_path = None\n",
        "\n",
        "    try:\n",
        "        response = requests.get(video_url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Save uploaded video to a temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_video:\n",
        "            temp_video.write(response.content)\n",
        "            temp_video_path = temp_video.name\n",
        "\n",
        "        # Set up video capture\n",
        "        cap = cv2.VideoCapture(temp_video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise HTTPException(status_code=400, detail=\"Unable to open video file\")\n",
        "\n",
        "        # Get video properties\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # Set up video writer\n",
        "        processed_video_path = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4').name\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        out = cv2.VideoWriter(processed_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "        # Initialize video processing variables\n",
        "        frame_count = 0\n",
        "        total_severity = 0\n",
        "        unique_potholes = set()\n",
        "\n",
        "        # Initialize masks for road and pothole tracking\n",
        "        global_road_mask = np.zeros((height, width), dtype=np.uint8)\n",
        "        global_pothole_mask = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "        # Set up ORB feature detector for homography\n",
        "        orb = cv2.ORB_create(500)\n",
        "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "        prev_frame_gray = None\n",
        "        prev_kp = None\n",
        "        prev_des = None\n",
        "\n",
        "        # Process video frame by frame\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Calculate homography between consecutive frames\n",
        "            homography_matrix = None\n",
        "            if prev_frame_gray is not None:\n",
        "                kp, des = orb.detectAndCompute(gray_frame, None)\n",
        "                if kp and des is not None and prev_kp and prev_des is not None:\n",
        "                    matches = bf.match(des, prev_des)\n",
        "                    if matches:\n",
        "                        matches = sorted(matches, key=lambda x: x.distance)[:50]\n",
        "\n",
        "                        if len(matches) > 10:\n",
        "                            src_pts = np.float32([kp[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "                            dst_pts = np.float32([prev_kp[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
        "                            homography_matrix, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
        "\n",
        "            # Update previous frame data\n",
        "            prev_frame_gray = gray_frame.copy()\n",
        "            prev_kp, prev_des = orb.detectAndCompute(gray_frame, None)\n",
        "\n",
        "            # Run YOLO model on current frame\n",
        "            results_list = model.predict(frame, show=False)\n",
        "\n",
        "            # Handle empty results\n",
        "            if not results_list:\n",
        "                out.write(frame)\n",
        "                continue\n",
        "\n",
        "            results = results_list[0]\n",
        "            binary_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
        "            detected_potholes = []\n",
        "\n",
        "            # Process bounding boxes\n",
        "            if hasattr(results, 'boxes') and results.boxes is not None:\n",
        "                for box in results.boxes:\n",
        "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                    confidence = float(box.conf[0])\n",
        "\n",
        "                    # Track unique potholes using grid-based approach\n",
        "                    center_x = (x1 + x2) // 2\n",
        "                    center_y = (y1 + y2) // 2\n",
        "                    pothole_id = (center_x // 10, center_y // 10)\n",
        "\n",
        "                    if pothole_id not in unique_potholes:\n",
        "                        unique_potholes.add(pothole_id)\n",
        "\n",
        "                    detected_potholes.append((x1, y1, x2, y2, confidence))\n",
        "\n",
        "            # Process segmentation masks\n",
        "            if hasattr(results, 'masks') and results.masks is not None and hasattr(results.masks, 'data'):\n",
        "                mask_data = results.masks.data.cpu().numpy()\n",
        "                for mask in mask_data:\n",
        "                    mask = (mask * 255).astype(np.uint8)\n",
        "                    mask_resized = cv2.resize(mask, (frame.shape[1], frame.shape[0]))\n",
        "                    binary_mask = cv2.bitwise_or(binary_mask, mask_resized)\n",
        "\n",
        "            # Apply homography to mask if available\n",
        "            if homography_matrix is not None:\n",
        "                try:\n",
        "                    binary_mask = cv2.warpPerspective(binary_mask, homography_matrix, (width, height))\n",
        "                except Exception:\n",
        "                    # Continue if homography transformation fails\n",
        "                    pass\n",
        "\n",
        "            # Update global masks\n",
        "            new_road_pixels = (frame[:, :, 0] > 50) | (frame[:, :, 1] > 50) | (frame[:, :, 2] > 50)\n",
        "            global_road_mask[new_road_pixels] = 255\n",
        "            global_pothole_mask = cv2.bitwise_or(global_pothole_mask, binary_mask)\n",
        "\n",
        "            # Calculate damage percentages\n",
        "            total_road_pixels = np.sum(global_road_mask > 0)\n",
        "            total_pothole_pixels = np.sum(global_pothole_mask > 0)\n",
        "\n",
        "            current_damage = (np.sum(binary_mask > 0) / np.sum(global_road_mask > 0)) * 100 if np.sum(global_road_mask > 0) > 0 else 0\n",
        "            total_damage = (total_pothole_pixels / total_road_pixels) * 100 if total_road_pixels > 0 else 0\n",
        "\n",
        "            # Apply damage calibration factor (preserved from original code)\n",
        "            calibrated_damage = total_damage * (1/2)\n",
        "\n",
        "            total_severity += current_damage\n",
        "\n",
        "            # Add information to frame\n",
        "            cv2.putText(frame, f\"Total Damage: {calibrated_damage:.2f}%\", (20, 30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "            cv2.putText(frame, f\"Current Frame: {current_damage:.2f}%\", (20, 60),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
        "\n",
        "            # Draw pothole contours\n",
        "            contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            for contour in contours:\n",
        "                cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "            # Add mask overlay\n",
        "            mask_colored = cv2.merge([np.zeros_like(binary_mask), np.zeros_like(binary_mask), binary_mask])\n",
        "            frame = cv2.addWeighted(frame, 0.6, mask_colored, 0.4, 0)\n",
        "\n",
        "            # Add confidence scores\n",
        "            for x1, y1, x2, y2, confidence in detected_potholes:\n",
        "                cv2.putText(frame, f\"{confidence:.2f}\", (x1, y1 - 10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "            # Ensure frame has correct dimensions\n",
        "            if frame.shape != (height, width, 3):\n",
        "                frame = cv2.resize(frame, (width, height))\n",
        "\n",
        "            # Write frame to output video\n",
        "            out.write(frame)\n",
        "\n",
        "        # Clean up video objects\n",
        "        cap.release()\n",
        "        out.release()\n",
        "\n",
        "        # Calculate final statistics\n",
        "        avg_severity = total_severity / frame_count if frame_count > 0 else 0\n",
        "        total_potholes_detected = len(unique_potholes)\n",
        "\n",
        "        # Convert processed video to base64\n",
        "        with open(processed_video_path, \"rb\") as video_file:\n",
        "            video_content = video_file.read()\n",
        "            video_base64 = base64.b64encode(video_content).decode('utf-8')\n",
        "\n",
        "        # Return results\n",
        "        return {\n",
        "            \"average_severity\": round(avg_severity, 2),\n",
        "            \"damaged_road_percentage\": round(total_damage * (1/2), 2),\n",
        "            \"video_base64\": video_base64,\n",
        "            \"total_potholes_detected\": total_potholes_detected,\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        return JSONResponse(\n",
        "            status_code=500,\n",
        "            content={\"detail\": f\"Error processing video: {str(e)}\",\n",
        "                     \"traceback\": traceback.format_exc()}\n",
        "        )\n",
        "\n",
        "    finally:\n",
        "        # Clean up temporary files\n",
        "        for path in [temp_video_path, processed_video_path]:\n",
        "            if path and os.path.exists(path):\n",
        "                try:\n",
        "                    os.remove(path)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "# For Jupyter/Colab, use this code for running the server\n",
        "# First, you'll need to install nest_asyncio:\n",
        "\n",
        "\n",
        "# Run the FastAPI app without blocking the notebook:\n",
        "def run_server():\n",
        "    # Import needed here to avoid circular imports\n",
        "    import uvicorn\n",
        "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000)\n",
        "    server = uvicorn.Server(config)\n",
        "    server.run()\n",
        "\n"
      ],
      "metadata": {
        "id": "XgIn7xZIC8mw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "server_thread = threading.Thread(target=run_server)\n",
        "server_thread.daemon = True\n",
        "server_thread.start()\n",
        "print(\"FastAPI server started in background thread on http://0.0.0.0:8000\")"
      ],
      "metadata": {
        "id": "XREvP4k6EC3Y",
        "outputId": "fcc65dbb-0942-4c5d-9249-afd55900a45d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI server started in background thread on http://0.0.0.0:8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utEzgYuSP2D4",
        "outputId": "1956d830-eac5-44a4-88ba-9ce4c058afdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model_loader.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_loader.py\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "def load_model():\n",
        "    \"\"\"\n",
        "    Load the YOLOv11 segmentation model\n",
        "\n",
        "    In Colab you may need to:\n",
        "    1. Install ultralytics: !pip install ultralytics\n",
        "    2. Download your model weights\n",
        "    \"\"\"\n",
        "    # Path to your model weights - update as needed\n",
        "    # If you have your model weights in Google Drive, you might need to mount it first\n",
        "    model_path = \"/content/best_remya.pt\"  # Update with actual path\n",
        "\n",
        "    # Check if model exists, otherwise download or raise error\n",
        "    if not os.path.exists(model_path):\n",
        "        # You can provide instructions for downloading from Google Drive here\n",
        "        raise FileNotFoundError(f\"Model file not found at {model_path}. Please upload your model weights.\")\n",
        "\n",
        "    # Load the model\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrGekfq2QLVo",
        "outputId": "fee9a1c7-6e67-4b60-f522-7ee56fffe93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# Setup ngrok tunnel\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your ngrok auth token (needed for longer session)\n",
        "# Get your auth token from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "!ngrok authtoken 2uqM61EwtXl1ckT4mXnjitdD3aQ_2WceDsogrzHe5C4ZG1UKw\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F08dvBRUQ2wc",
        "outputId": "e82f6826-ee10-4a75-8893-5e99f89da363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://4527-104-196-44-117.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "# Start ngrok tunnel to port 8000\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(\"Public URL:\", ngrok_tunnel.public_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok\n"
      ],
      "metadata": {
        "id": "D9Be3FJmzTwN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usgRQNlGQ7IK"
      },
      "outputs": [],
      "source": [
        "# Launch the FastAPI app\n",
        "!uvicorn main:app --host 0.0.0.0 --port 8000"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOy9viyyFy016YK7Ype8HFR"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}